import matplotlib.pyplot as plt
import matplotlib.lines as lines
import matplotlib.dates as mdates
import _pickle as pickle
import numpy as np
import cv2
import json
import io
import os
import torch
import requests
from datetime import datetime

from scipy.stats.kde import gaussian_kde
from scipy.stats import norm
import matplotlib.gridspec as grid_spec


from sklearn.linear_model import LinearRegression

import colorsys
"""
The basic idea is to create a grid of metric results, with each row corresponding to
a collection and each column corresponding to a metric readout. Each individual 
row,column combo will be generated by a function that takes in the metric set
and returns a figure. Then the overall figure can just plot these as a subplot
Perhaps one additional row should be added with an explanation (as text) of each plot
    PLOT 0 - Summary Spiderplot    
    PLOT 1 - MOT metrics as bar chart, with bar colored in red-green range, and label written on bar (horizontal)
    PLOT 2 - State Errors as ridgeline plot with axis in feet and other statistics shown
    PLOT 3 - Confusion Matrix
    PLOT 4 - Histogram of any of the metrics for which we record all values (vx, ax, theta, x_travelled, y_travelled)
    PLOT 5 - bar chart of any other unsupervised metrics 
"""

"""
There should also be a supplementary file with, for each metric, a description, and a best and worst value (for coloration)
"""

def random_pallette(length):
    sat = 0.2
    var = 0.8
    
    # c_base = np.array([[200,100,100],
    #                    [100,200,100],
    #                    [0,0,255]])
    colors = []
    start_hue =  np.random.rand()

    for i in range(length):
        hue = (start_hue + (length//3)*i/length)%1
        color =    colorsys.hsv_to_rgb(hue,sat,var)
        color = np.array(color) * 255

        colors.append(color)
    return np.stack(colors)

#%% Globals 
global results_dir
results_dir = "/data/"

global dpi
dpi = 162
global scale 
scale = 50
#plt.style.use("bmh")
global MD
MD = {
    "precision":{"text":"Precision","best":1,"bad":0.5},
    "recall":{"text":"Recall","best":1,"bad":0.5},
    "true_negative_rate":{"text":"TNR","best":1,"bad":0},
    "pred_match":{"text":"Pred Match Rate", "best":1,"bad":0.5},
    "gt_match":{"text":"GT Match Rate","best":1,"bad":0.5},
    "motp":{"text":"MOTP","best":1,"bad":0.5},
    "mota":{"text":"MOTA","best":1,"bad":0.5},
    "idr":{"text":"ID-Recall","best":1,"bad":0.5},
    "idp":{"text":"ID-Precision","best":1,"bad":0.5},
    "idf1":{"text":"ID-F1","best":1,"bad":0.5},
    "avg_ax":{"text":"Average Acceleration per traj"},
    "avg_vx":{"text":"Average Speed per traj"},
    "vx":{"text":"Velocity"},
    "ax":{"text":"Acceleration"},
    "x_traveled":{"text":"Trajectory Length","best":2000,"bad":300},
    "x_traveled_avg":{"text":"Trajectory Length","best":2000,"bad":300},
    "bps":{"text":"Hz","best":30,"bad":1},
    "traj_count":{"text":"Trajectories","best":np.nan},
    "x_variation":{"text":"X Variation","best":1,"bad":1.2},
    "y_variation":{"text":"Y Variation","best":0,"bad":50},
    "duration_avg":{"text": "Duration", "best":np.nan},
    "percent_backwards":{"text":"Backwards %","best":0,"bad":1},
    "overlaps_per_object":{"text":"Overlaps/Traj","best":0,"bad":1},
    "mostly_tracked%":{"text":">80% Tracked","best":1,"bad":0.2},
    "mostly_lost%":{"text":"<20% Tracked","best":0,"bad":0.4},
    "num_switches_per_gt":{"text":"Switches per GT","best":0,"bad":2},
    "num_fragmentations_per_gt":{"text":"Frag per GT","best":0,"bad":2},
    "pred_avg_matches":{"text":"GT IDs / Pred","best":1,"bad":2},
    "gt_avg_matches":{"text":"Pred IDs / GT","best":1,"bad":2},
    "per_gt_recall":{"text":"Recall / GT","best":1,"bad":0},
    "per_pred_precision":{"text":"Precision / Pred","best":1,"bad":0},
    "residual":{"text": "Post Residual"},
    
    "distance_score":{"text": "Distance"},
    "backward_score":{"text": "Backward"},
    "acceleration_score":{"text": "Acceleration"},
    "rotation_score":{"text": "Rotation"},
    "conflict_score":{"text": "Overlapping"},
    "feasibility_score":{"text": "Feasible"},
    
    }

global color_pallette 
# color_pallette = np.array([[117,158,186],   # for primary data
#                            [160,120,120],   # for baseline / old data
#                            [210,220,220],   # for other plots
#                            [220,220,210],   # for other plots
#                            [220,210,220],   # for other plots
#                            [110,120,120],   # for other plots
#                            [120,110,120],   # for other plots
#                            [120,120,110],   # for other plots
#                            [220,220,220],   # for cmap
#                            [255,255,255]    # for pane default color
#                            ])
color_pallette = np.array([[131, 121, 163], # for primary data
                           [163, 153, 116], #  for baseline / old data
                           [210,220,220],   # for other plots
                           [220,220,210],   # for other plots
                           [220,210,220],   # for other plots
                           [110,120,120],   # for other plots
                           [120,110,120],   # for other plots
                           [120,120,110],   # for other plots
                           [220,220,220],   # for cmap
                           [255,255,255]    # for pane default color
                           ])
color_pallette = random_pallette(10)
color_pallette[-2:,:] = np.array([[220,220,220],[255,255,255]])

global primary_colors
primary_colors = (np.random.rand(8,3)-0.5) * 20 + color_pallette[0][None,:]

global secondary_colors
secondary_colors = (np.random.rand(8,3)-0.5) * 20 + color_pallette[1][None,:]


# primary_colors = primary_colors[:,::-1]
# secondary_colors = secondary_colors[:,::-1]
# color_pallette = color_pallette[:,::-1]


global cmap
#cmap = lambda x: np.array([(255*(1-x),140,255*x)]).astype(np.uint8).tolist()
cmap = lambda x: color_pallette[0]*(x) + color_pallette[-2]*(1-x)

global classmap
classmap = ["sedan","midsize","van","pickup","semi","truck"]




#%% DONE

def f2a(fig):
    io_buf = io.BytesIO()
    fig.savefig(io_buf, format='raw')#, dpi=dpi)
    io_buf.seek(0)
    img_arr = np.reshape(np.frombuffer(io_buf.getvalue(), dtype=np.uint8),
                         newshape=(int(fig.bbox.bounds[3]), int(fig.bbox.bounds[2]), -1))
    io_buf.close()
    
    # RGB to BGR
    img_arr = img_arr.copy()
    temp = img_arr[:,:,0].copy()
    img_arr[:,:,0] = img_arr[:,:,2]
    img_arr[:,:,2] = temp
    return img_arr

def gen_title(results,figsize):
    name = results[0]["name"]
    iou = results[0]["iou_threshold"]
    try:
        comment = results[0]["description"]
    except:
        comment = ""
    try:
        gt_dataset = results[0]["gt"]
    except:
        gt_dataset = "No GT data"
    
    
    fig = plt.figure(figsize=(figsize[0]/scale,figsize[1]/scale))
    
    fig.text(0.01,0.8,"Collection: ",fontsize = 2500/scale)
    fig.text(0.25,0.8,"{}".format(name),fontsize = 2500/scale,color = color_pallette[0]/255)

    fig.text(0.01,0.3,"Notable changes:",fontsize = 1500/scale)
    fig.text(0.25,0.3,"{}".format(comment),fontsize = 1500/scale,wrap = True, va = "top")

    fig.text(0.01,0.45,"GT IOU:",fontsize = 1500/scale)
    fig.text(0.25,0.45,"{} ({})".format(iou,gt_dataset),fontsize = 1500/scale)

    if len(results) > 1:
        baseline_name = results[1]["name"]
        fig.text(0.01,0.6,"Baseline: ",fontsize = 1500/scale)
        fig.text(0.25,0.6,"{}".format(baseline_name),fontsize = 1500/scale,color = color_pallette[1]/255)

    return f2a(fig)

def unsup_title(results,figsize):
    fig = plt.figure(figsize=(figsize[0]/scale,figsize[1]/scale))
    fig.text(0.5,0.5,"Unsupervised Statistics",fontsize = 2500/scale, va = "center",ha = "center")
    return f2a(fig)

def sup_title(results,figsize):
    fig = plt.figure(figsize=(figsize[0]/scale,figsize[1]/scale))
    fig.text(0.5,0.5,"Supervised Metrics",fontsize = 2500/scale, va = "center",ha = "center")
    return f2a(fig)



def unsup_hist2(results,figsize):
    to_plot = ["distance_score","backward_score","acceleration_score","rotation_score","feasibility_score"] #"conflict_score_raw",
    units = ["","","","","",""]
    title = "Unsupervised Score"
    
    xrange_clip = [[0,1],[0,1],[0,1],[0,1],[0,1],[0,1]]
    
    return unsup_hist(results,figsize,to_plot,units,xrange_clip,title,uniform_x = True)


def unsup_hist(results,
               figsize,
               to_plot = ["x_traveled","avg_vx","avg_ax","vx","ax","residual"],
               units = ["ft","ft/s","ft/$s^2$","ft/s","ft/$s^2$","ft"],
               xrange_clip = [[-500,2000],[0,150],[-8,8],[0,150],[-8,8],[0,100]],
               title = "Trajectory Attribute Histograms",
               uniform_x = False
               ):

    if ("residual" not in results[0].keys() or sum(results[0]["residual"]["raw"]) == 0) and "residual" in to_plot:
        to_plot = ["x_traveled","avg_vx","avg_ax","vx","ax"]
    
    
    fig = plt.figure(figsize =(figsize[0]/scale,figsize[1]/scale))
    # ax = fig.add_subplot(111)
    # ax.spines.top.set_visible(False)
    # ax.spines.left.set_visible(True)
    # ax.spines.right.set_visible(False)
    
    # get data
    data = [np.array(results[0][key]["raw"]) for key in to_plot]
    data = [data[i] -0.01*np.random.rand(*data[i].shape) for i in range(len(data))]
    
    #data = np.stack(data)
    #xx = np.arange(-8,8,0.05)
    data_pdf = []
    for i in range(len(data)):
        
        pdf = gaussian_kde(data[i])
        xx = np.arange(np.min(data[i]),np.max(data[i]),1)
        xx = np.linspace(np.min(data[i]),np.max(data[i]),200)
        data_pdf.append([xx,pdf(xx)])
            
    #data_pdf = np.stack(data_pdf)
    
    if len(results) > 1:
        data2 = [np.array(results[1][key]["raw"]) for key in to_plot]
        data2 = [data2[i] -0.01*np.random.rand(*data2[i].shape) for i in range(len(data2))]
        #data2 = np.stack(data2)
        data2_pdf = []
        for i in range(len(data2)):
            try:
                pdf = gaussian_kde(data2[i])
                xx = np.arange(np.min(data2[i]),np.max(data2[i]),1)
                xx = np.linspace(np.min(data[i]),np.max(data[i]),200)
                data2_pdf.append([xx,pdf(xx)])
            except:
                data2_pdf.append([[0],[0]])
        #data2_pdf = np.stack(data2_pdf)
    
    gs = (grid_spec.GridSpec(len(data),1))
    
    #creating empty list
    ax_objs = []
    for didx in range(len(data_pdf)):
        
        if to_plot[didx] not in results[0].keys():
            continue
        
        xx,dataD = data_pdf[didx]
        # creating new axes object and appending to ax_objs
        ax_objs.append(fig.add_subplot(gs[didx:didx+1, 0:]))
        
        max_val = np.max(dataD)
        xr = [min(xx),max(xx)]

        # plotting the distribution
        # filling the space beneath the distribution
        if len(results) > 1 and to_plot[didx] in results[1].keys():
            xx2,dataD2 = data2_pdf[didx]
            ax_objs[-1].fill_between(xx2,dataD2,alpha = 1,color = color_pallette[1]/255)
            ax_objs[-1].plot(xx2,dataD2,color = color_pallette[1]/255)
            
            max_val = max(np.max(dataD),np.max(dataD2))
            xr = [min(min(xx),min(xx2)),max(max(xx),max(xx2))]
            
        ax_objs[-1].fill_between(xx,dataD,alpha = 0.5,color = color_pallette[0]/255)
        ax_objs[-1].plot(xx,dataD,color = "black",linewidth = 2)


    
        # setting uniform x and y lims
        xr[0] = max(xr[0],xrange_clip[didx][0])
        xr[1] = min(xr[1],xrange_clip[didx][1])
        
        if uniform_x:
            xr = xrange_clip[didx]
        

        ax_objs[-1].set_xlim(xr[0],xr[1])
        ax_objs[-1].set_ylim(0,max_val)
    
        # make background transparent
        rect = ax_objs[-1].patch
        rect.set_alpha(0)
        
        # remove borders, axis ticks, and labels
        ax_objs[-1].set_yticklabels([])
        ax_objs[-1].set_yticks([])
        ax_objs[-1].set_ylabel('')
        
        #if didx == data.shape[0]-1:
        ax_objs[-1].tick_params(axis='x', labelsize=1000/scale,length = 500/scale )
        ax_objs[-1].set_xlabel("{}".format(units[didx]), fontsize = 1500/scale)
        # else:
        #     ax_objs[-1].set_xticklabels([])
        #     ax_objs[-1].tick_params(axis='x', length = 200/scale )

        
        spines = ["top","right","left"]#,"bottom"]
        for s in spines:
            ax_objs[-1].spines[s].set_visible(False)
        ax_objs[-1].text(xr[0],max_val/2,MD[to_plot[didx]]["text"],fontweight="bold",fontsize = 1500/scale,va="bottom")
        #ax_objs[-1].axvline(x = 0, ymax = 0.8, linestyle = ":",color = (0.2,0.2,0.2))
        
        
        # get mean,MAE, stddev, max
        mean = np.mean(data[didx])
        MA  = np.mean(np.abs(data[didx]))
        stddev = np.std(data[didx])
        maxx = np.max(np.abs(data[didx]))
        
        xv = xr[0] #+  0.2*(xr[1] - xr[0])
        ax_objs[-1].text(xv,max_val/2,               "Mean:     {:.2f}{}".format(mean,units[didx]),fontsize = 1000/scale,va="top")
        ax_objs[-1].text(xv,max_val/2-(0.05*max_val),"Mean Abs: {:.2f}{}".format(MA,units[didx]),fontsize = 1000/scale,va="top")
        ax_objs[-1].text(xv,max_val/2-(0.1*max_val), "Stdev:    {:.2f}{}".format(stddev,units[didx]),fontsize = 1000/scale,va="top")
        ax_objs[-1].text(xv,max_val/2-(0.15*max_val),"Max:      {:.2f}{}".format(maxx,units[didx]),fontsize = 1000/scale,va="top")
        
        if len(results) > 1:
            mean = np.mean(data2[didx])
            MA  = np.mean(np.abs(data2[didx]))
            stddev = np.std(data2[didx])
            maxx = np.max(np.abs(data2[didx]))
            
            xv = xr[0] + 0.16*(xr[1] - xr[0])
            # may need a black border
            
            ax_objs[-1].text(xv,max_val/2,     " ({:.2f}{})".format(mean,units[didx]),fontsize = 1000/scale,va="top",ha="left", color=color_pallette[1]/255,bbox=dict(facecolor="white",edgecolor="white",alpha=0.7))
            ax_objs[-1].text(xv,max_val/2-(0.05*max_val)," ({:.2f}{})".format(MA,units[didx]),fontsize = 1000/scale,va="top",ha="left", color= color_pallette[1]/255,bbox=dict(facecolor="white",edgecolor="white",alpha=0.7))
            ax_objs[-1].text(xv,max_val/2-(0.1*max_val), " ({:.2f}{})".format(stddev,units[didx]),fontsize = 1000/scale,va="top",ha="left", color= color_pallette[1]/255,bbox=dict(facecolor="white",edgecolor="white",alpha=0.7))
            ax_objs[-1].text(xv,max_val/2-(0.15*max_val)," ({:.2f}{})".format(maxx,units[didx]),fontsize = 1000/scale,va="top",ha="left", color= color_pallette[1]/255,bbox=dict(facecolor="white",edgecolor="white",alpha=0.7))

    plt.tight_layout()
    gs.update(hspace= -0.2)
    
    
    fig.text(0.5,0.95,title,fontsize = 2000/scale,ha = "center")
    return f2a(fig)



def chart_unsup(results,figsize):
    
    c_scale = 50000
    
    fig = plt.figure(figsize =(figsize[0]/scale,figsize[1]/scale))
    ax = fig.add_subplot(111)
    ax.set_position([0,0,1,1])
    ax.axis("off")

    # assemble list of metrics with ideal value (or -1 if none), new value, [old value]
    to_list = ["traj_count","bps","x_variation","y_variation","duration_avg","x_traveled_avg","percent_backwards","overlaps_per_object"]
    coll_names = [result["name"] for result in results]
    cell_text = []
    
    
    data = np.zeros([len(to_list),len(coll_names)+1])
    
    
    
    for qidx,quant in enumerate(to_list):
        row_text = []
        for ridx,result in enumerate(results):
            if quant in result.keys():
                data[qidx,ridx] = result[quant]
            else:
                data[qidx,ridx] = 0
        data[qidx,-1] = MD[quant]["best"]
    
    # normalize data by max data[:,0]
    data += 0.0000001
    data_norm = data / np.max(data[:,:2],axis = 1)[:,None]
    data_norm = data_norm.clip(0.001)
    
    w2h = figsize[0] / figsize[1]
    
    ns = len(to_list)
    nr = np.ceil(np.sqrt(ns/w2h)) 
    nc = np.ceil(  ns/nr)
    
    assert nc*nr >=ns, "Not enough cells for data"
    
    for idx in range(ns):
        for didx in range(len(results)-1,-1,-1):
            ax.scatter(idx//nr,idx%nr,s=data_norm[idx,didx]*c_scale,color = [color_pallette[didx]/255], alpha = 0.6)
        
        
        tshift = 0.2
        ax.text(idx//nr,idx%nr+tshift,MD[to_list[idx]]["text"],va="bottom",ha="center", fontsize = 1500/scale)
        txt = "{:.2f} ".format(data[idx,0])
        ax.text(idx//nr,idx%nr+tshift,txt,va="top",ha="right", fontsize = 1000/scale)
    
        if len(results) > 1:
            txt = " $\leftarrow$ ({:.2f})".format(data[idx,1])
            ax.text(idx//nr,idx%nr+tshift,txt,va="top",ha="left", fontsize = 1000/scale)
           
        best = data_norm[idx,2]
        if not np.isnan(best):
            # if best == 0:
            #     best += 0.0001
            ax.scatter(idx//nr,idx%nr,s=best*c_scale,facecolors='none', edgecolors=[0,0,0],linewidth = 2)
    
    ax.set_xlim([-0.5,nc-0.5])
    ax.set_ylim([-0.5,nr-0.3])
    
    return f2a(fig)






def gen_pane(results = [],
             size = [2160,3840],
             pane_layout = None,
             pane_functions = None,
             close = 0
             ):
    
    """
    Generates a dashboard layout with each of the specified panes filled by the 
    corresponding matplotlib plot function
    results - results dictionary generated by evaluate.py and loaded from pickle file
    pane_layout - iterable of item size 4 with grid x, grid y, width, height of each pane
    pane_functions - function used to create matplotlib (or other) figure to fill said pane (takes size as input)
    color_pallette - np.array.tolist() of size n,3
    color_spectrum - matplotlib colormap, for functions requiring spectrum - based color
    
    Importantly, the size for each plot is computed flexibly based on pane sizes and passed to the corresponding generation function,
    creating a tight layout - nice!
    """
    
    pad = 20
    shadow_pad = 18
    
    # TODO make pallette color [-1]
    dashboard = np.zeros([size[0],size[1],3]).astype(np.uint8) + 220
    
    # create placeholder panes
    pane_size = []
    pane_loc = []
    for pane in pane_layout:
        color = color_pallette[-1].tolist()
        pane_coords = (int(pane[0]*size[0]/9 + pad),int(pane[1]*size[1]/16) + pad), (int((pane[0] + pane[2])*size[0]/9 - pad),int((pane[1] + pane[3])*size[1]/16 - pad))
        shadow_coords = (int(pane[0]*size[0]/9 + pad),int(pane[1]*size[1]/16) + pad), (int((pane[0] + pane[2])*size[0]/9 - shadow_pad),int((pane[1] + pane[3])*size[1]/16 - shadow_pad))

        pane_size.append([pane_coords[1][0] - pane_coords[0][0], pane_coords[1][1] - pane_coords[0][1]])
        pane_loc.append(pane_coords)
        
        dashboard = cv2.rectangle(dashboard,shadow_coords[0],shadow_coords[1],(190,190,190),-1)
        dashboard = cv2.rectangle(dashboard,pane_coords[0],pane_coords[1],color,-1)
    
    for idx,fn in enumerate(pane_functions):
        pane_coords = pane_loc[idx]
        pane_im = fn(results,pane_size[idx])
        if pane_im is not None:
            #pane_im = cv2.imload("temp.png")
            pane_im = cv2.resize(pane_im,pane_size[idx])
            dashboard[pane_coords[0][1]:pane_coords[1][1],pane_coords[0][0]:pane_coords[1][0],:] = pane_im[:,:,:3]
        
    
    
    # display image
    dashboard = cv2.resize(dashboard,(int(size[1]*0.95),int(size[0]*0.95)))
    # cv2.imshow("frame",dashboard)
    # cv2.waitKey(close)
    # cv2.destroyAllWindows()
    
    
    
    now = datetime.now()
    now = now.strftime("%Y-%m-%d_%H-%M-%S")
    f_name = "push_images/{}.png".format(now)
    print(f_name)
    cv2.imwrite(f_name,dashboard)
    
    now = now.strftime("%Y-%m-%d_%H-%M-%S")
    url = 'http://viz-dev.isis.vanderbilt.edu:5991/upload?type=track_eval'
    files = {'upload_file': open(f_name,'rb')}
    ret = requests.post(url, files=files)
    print(ret)
    if ret.status_code == 200:
        print('Uploaded!')

    
def dummy(a,b):
    pass



def lrk(results):
    # list result keys
    keylist = list(results[0].keys())
    keylist.sort()
    [print(key) for key in keylist ]
    
  

#%% TO BE IMPLEMENTED
    
def main(mode = "latest v latest", close = 0):
    print("Generating Results Dashboard...")
    

    results = [
        # "/home/derek/Documents/i24/trajectory-eval-toolkit/data/eval_results/unwieldy_markhor--RAW_GT2__escalates.cpkl",
        # "/home/derek/Documents/i24/trajectory-eval-toolkit/data/eval_results/unwieldy_markhor--RAW_GT2.cpkl",
        #"/home/derek/Documents/i24/trajectory-eval-toolkit/data/eval_results/sanctimonious_beluga--RAW_GT1__administers.cpkl",
        #"/home/derek/Documents/i24/trajectory-eval-toolkit/data/eval_results/sympathetic_cnidarian--RAW_GT1__juxtaposes.cpkl"
        "data/2022-12-01_17-17-29_635997ddc8d071a13a9e5293.pkl",
        "data/2022-12-02_13-45-08_635997ddc8d071a13a9e5293.pkl"
        ]
    #results.reverse()
    
    

    for i in range(len(results)):
        
        with open(results[i],"rb") as f:
            results[i] = pickle.load(f)

    # pane = origin x, origin y, width , height
    panes = np.array([[0,0,4,1], # Title   # 
                      # [0,1,4,3], # Spider
                      [0,4,4,5], # Unsup chart
                      
                      [4,0,4,6], # Unsupervised Histograms 
                      [4,6,4,3], # Death Pie
                      
                      # [8,0,4,6],     # Unsupervised Histograms 2 (feasibility)    #
                      # [8,6,4,3],     # Class info

                     
                      # [12,0,4,3], # State error                #  
                      # [12,3,4,3], # MOT chart
                      # [12,6,4,3], # Additional Hover Info
                      ])
    
    pane_functions = [gen_title,    
                      chart_unsup,
                      unsup_hist,
                      unsup_hist2, # feasibility
                      # dummy, # eventually class dist
                      # dummy,# eventually speed v time
                      # dummy,#eventually throughput v time
                      # dummy,# eventually density v time 
                      ]
    
    
    gen_pane(results = results,
             pane_layout = panes,
             pane_functions= pane_functions,
             close = close
             )
    
    
if __name__ == "__main__":
    main()

   